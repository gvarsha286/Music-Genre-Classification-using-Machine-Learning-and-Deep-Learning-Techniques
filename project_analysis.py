# -*- coding: utf-8 -*-
"""project analysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1vgEOtRckPnkPUVjb9JQStjsi7Jtg13kS
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import RobustScaler
from sklearn.decomposition import PCA
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
from scipy.stats import zscore
!pip install fasttext
import fasttext
import os
# %matplotlib inline

from google.colab import drive
drive.mount('/content/drive')

df = pd.read_csv('/content/drive/MyDrive/music_genre.csv')

import pandas as pd
import matplotlib.pyplot as plt
df = pd.read_csv('/content/drive/MyDrive/music_genre.csv')

# Count the number of occurrences of each category in the music_genre column
counts = df['music_genre'].value_counts()

# Create a bar plot of the counts with different colors for each category
colors = ['blue', 'green', 'red', 'orange', 'purple'] # list of colors
counts.plot(kind='bar', color=colors)

# Set the title and axis labels
plt.title('Distribution of Music Genres')
plt.xlabel('Music Genre')
plt.ylabel('Count')

# Rotate the x-axis labels to make them more readable
plt.xticks(rotation=90)

# Display the bar plot
plt.show()

df.columns
df.shape

df.info()

df.isna().sum()

df[df.isnull().any(axis=1)]

"""**There are 5 rows that caontain null values we will eliminate them now**"""

df.dropna(inplace=True)
df.reset_index(drop=True, inplace=True)
df.info()

df.head()

df.describe()

corr_matrix = df.corr()
sns.heatmap(corr_matrix, cmap="YlGnBu")

# Show the plot
plt.show()

# Create a scatter plot of energy and loudness
plt.scatter(df['energy'], df['loudness'])

# Add labels and title
plt.xlabel('Energy')
plt.ylabel('Loudness')
plt.title('Energy vs. Loudness')

# Show the plot
plt.show()

df.describe(include=['O'])

"""We can see that there are 17 features and one label column (music_genre). Out of the features, 12 are numerical (one of which, tempo, is missclassified ), and 5 are categorical.

We can also already see hints to hidden missing values in 2 features ('tempo', 'artist_name').

"""

df['music_genre'].value_counts()   # checking if the data is balanced data

"""There are 10 different genres with equal distribution (balanced data). This means the accuracy score will be a good metric to use."""

data = df.drop(columns=['instance_id'])   # since we dont need this column for our analysis we will drop this col

"""# Let's explore features one by one

### Artist
"""

print(f"There are {data['artist_name'].nunique()} unique artists in the set")

data['artist_name'].describe()

music = data.drop(data[data["artist_name"] == "empty_field"].index)

top_20_artists = music["artist_name"].value_counts()[:20].sort_values(ascending = True)

import matplotlib.pyplot as plt

plt.barh(top_20_artists.index, top_20_artists)
plt.xlabel("Number of songs per artist")
plt.title("Songs per artist")
plt.grid(False)
plt.show()

"""It seems the dataset was compiled by Japanese authors or in Japan since several artists in top20 are from the Land of the Rising Sun"""

missing_artist = data[data['artist_name'] == 'empty_field']
missing_artist.head()

print(f"Percent of missing artist names: {(missing_artist.shape[0]/data.shape[0])*100:2.4}%")

"""5% of the observations are missing the artist's names (marked as 'empty_field'), but these entries are still valid otherwise. we will not drop these observations."""

data[data['artist_name'] != 'empty_field'].groupby('artist_name')['music_genre'].nunique().value_counts(normalize=True)
## For the entries that do contain an artist's name, it seems that a song that comes from a particular artist has an
#~80% chance of belonging to one specific genre.

"""# Track name"""

data['track_name'].describe()

data['length_track_name'] = data['track_name'].str.len()

data.groupby('music_genre')['length_track_name'].describe()

plt.figure(figsize=(16,8))
sns.boxplot(data=data, x='music_genre', y='length_track_name')
plt.show()

data[data['music_genre'] == 'Anime'].head()

os.system(f"wget https://dl.fbaipublicfiles.com/fasttext/supervised-models/lid.176.ftz")

PRETRAINED_MODEL_PATH = 'lid.176.ftz'
model = fasttext.load_model(PRETRAINED_MODEL_PATH)

def find_japanese(df):
    '''
    returns a 1D-array of 0's ans 1's, as well as the confidence of each prediction.
    1 - if either the artist or track name is written in japanese.
    0 - otherwise
    '''
    jap = []
    confidence = []

    for _, row in df.iterrows():
        pred_track, confidence_track = model.predict(row['track_name'])
        pred_track = pred_track[0].split('__')[-1]
        pred_artist, confidence_artist = model.predict(row['artist_name'])
        pred_artist = pred_artist[0].split('__')[-1]

        # check the confidence of the language detection
        if (pred_track == 'ja') or (pred_artist == 'ja'):
            jap.append(1)
            confidence.append(np.max([confidence_track[0], confidence_artist[0]]))
        else:
            jap.append(0)
    return jap, np.array(confidence)

data['Japanese'], confidence = find_japanese(data[['artist_name', 'track_name']])

print(f"The average confidence level for the japanese predictions is {confidence.mean():1.2} +\- {confidence.std():1.2}")

data.groupby('music_genre')['Japanese'].value_counts(normalize=True)

data = data.drop(columns=['artist_name', 'track_name'])

"""More than 20% of the Anime tracks are indeed written in Japanese, a much higher percentage than all the other music genres combined. This could indeed help us identify the Anime genre.

# popularity:
"""

data.groupby('music_genre')['popularity'].describe()

plt.figure(figsize=(16,8))
sns.boxplot(data=data, x='music_genre', y='popularity')
plt.show()

"""Rap, Hip-Hop and Rock seem to be the most popular genres, while Anime, Blues and Classical are the least popular. The other 4 genres are somewhere in between.

# acousticness:
"""

data.groupby('music_genre')['acousticness'].describe()

plt.figure(figsize=(16,8))
sns.boxplot(data=data, x='music_genre', y='acousticness')
plt.show()

"""Interestingly, classical music is once again quite the outlier. (Also Jazz, to a lesser extant)

## Danceability:
"""

data.groupby('music_genre')['danceability'].describe()

plt.figure(figsize=(16,8))
sns.boxplot(data=data, x='music_genre', y='danceability')
plt.show()

"""Classical music sticks out again, but Rap and Hip-Hop can also be distinguished from the rest (they seem to go together often)

## Duration:
"""

data.groupby('music_genre')['duration_ms'].describe()

miss_duration = data[data['duration_ms'] == -1].shape[0]
num_obs_tot = data.shape[0]
print(f"There are {miss_duration} missing values, which accounts for {(miss_duration/num_obs_tot)*100:2.4}% of the data points.")

"""Almost 10% of the entries are missing a duration. We don't want to remove such a large amount of observations, so we'll fill in the missing values with the median."""

# fill in median for missing values
mask_duration = data['duration_ms'] != -1
median_duration = data.loc[mask_duration, 'duration_ms'].median()
data.loc[~mask_duration, 'duration_ms'] = median_duration

sns.set_style("whitegrid")  # Set the plot style
plt.figure(figsize=(12,11))  # Set the figure size
sns.boxplot(x='music_genre', y='duration_ms', data=data)
plt.xlabel('Music Genre')
plt.ylabel('Duration (seconds)')
plt.title('Distribution of Music Duration by Genre')
plt.show()

"""## Energy:"""

data.groupby('music_genre')['energy'].describe()

plt.figure(figsize=(16,8))
sns.boxplot(data=data, x='music_genre', y='energy')
plt.show()

"""As usual, classical music stands out (and Jazz to a much lesser degree). Rap and Hip-Hop still match each other.

## Instrumentalness:
"""

data.groupby('music_genre')['instrumentalness'].describe()

plt.figure(figsize=(16,8))
sns.boxplot(data=data, x='music_genre', y='instrumentalness')
plt.show()

sns.histplot(x='instrumentalness',data=data)

inst_0 = data[data['instrumentalness'] == 0].shape[0]
num_obs = data.shape[0]
print(f"There are {inst_0} observations with 0.0 instrumentalness, which accounts for {(inst_0/num_obs)*100:2.4}% of the data points")

"""There are 15001 observations with 0.0 instrumentalness, which accounts for 30.0% of the data points

Such a large number of 0.0 entries likely indicates missing values rather than real data points. Since this is a 3rd of our observations, we won't fill in missing values. Instead, we'll discard this feature entirely.
"""

data = data.drop(columns=['instrumentalness'])

"""## Key:"""

data['key'].unique()

sns.catplot(x="music_genre", hue="key",data=data, kind="count",height=5, aspect=3.0, palette = 'Set1');

data.groupby('music_genre')['key'].describe()

"""Different genres have noticeably different spreads. We'll keep this feature, but use One Hot Encoding to make it useful."""

data = pd.get_dummies(data, drop_first=True, prefix='key', columns=['key'])

"""## Liveness:"""

data.groupby('music_genre')['liveness'].describe()

plt.figure(figsize=(16,8))
sns.boxplot(data=data, x='music_genre', y='liveness')
plt.show()

data.groupby('music_genre')['liveness'].plot.kde()
plt.legend()
plt.xlim([0,1])
plt.show()

"""The distributions seem similarly skewed for all genres, so this feature will likely not contribute much to the model. We'll try both with and without this feature.

## Loudness:
"""

data.groupby('music_genre')['loudness'].describe()

plt.figure(figsize=(16,8))
sns.boxplot(data=data, x='music_genre', y='loudness')
plt.show()

"""As usual, classical music is far from the rest, with Jazz (and Blues) also differing from the rest somewhat.

## Mode:
"""

data['mode'].unique()

data.groupby('music_genre')['mode'].describe()

plt.figure(figsize=(10,5))
sns.countplot(x="music_genre", hue="mode",data=data)
plt.legend(loc=0)
plt.show()

"""All genres seem to have a prefererence for the "Major" mode, but to different degrees. It is the most pronounced in the Country genre. We'll use this feature after one hot encoding"""

# One Hot Encoding
data = pd.get_dummies(data, drop_first=True, columns=['mode'])

"""## Speechiness:"""

data.groupby('music_genre')['speechiness'].describe()

plt.figure(figsize=(16,8))
sns.boxplot(data=data, x='music_genre', y='speechiness')
plt.show()

"""This feature should contribute especially to identifying Hip-Hop and Rap.

## Tempo:
"""

data.groupby('music_genre')['tempo'].describe()

"""This feature should be numeric. The "?" is a missing value."""

print(f"This feature contains {(data[data['tempo'] == '?'].shape[0]/data.shape[0])*100:2.4}% missing values")

"""This feature contains 9.96% missing values"""

# replace "?" with np.nan and correctly classify the feature:
data.loc[data['tempo'] == '?', 'tempo'] = np.nan
data = data.astype({'tempo': np.float64})

data.groupby('music_genre')['tempo'].describe()

plt.figure(figsize=(16,8))
sns.boxplot(data=data, x='music_genre', y='tempo')
plt.show()

"""The variation between genres is not great. We'll fill missing values with the median, but consider dropping the feature altogether in the future."""

median_tempo = data['tempo'].median()
data['tempo'] = data['tempo'].fillna(median_tempo)

"""## Obtained date:"""

data['obtained_date'].unique()

data.groupby('music_genre')['obtained_date'].describe()

"""Only gives the 4 dates at which the data was obtained. Not useful to us, so we'll drop it."""

data = data.drop(columns=['obtained_date'])

"""## Valence:"""

data.groupby('music_genre')['valence'].describe()

plt.figure(figsize=(16,8))
sns.boxplot(data=data, x='music_genre', y='valence')
plt.show()

"""Again, only classical music truly stands out from the rest.

Features:

**Useful features:**

1.popularity - left as is.

2.acousticness - left as is.

3.danceability - left as is.

4.duration_ms - 10% of the entries had missing values, they were filled in with the median.

5.energy - left as is.

6.key - a categorical column containing 12 unique categories. One hot encoding was used.

7.liveness - left as is with a caveat: may be removed later on due to a lack of variance between genres.

8.loudness - left as is.

9.mode - a categorical column containing only 2 unique categories. One hot encoding was used.

10.speechiness - left as is.

11.tempo - contained 10% missing values and missclassified as catagorical. The missing values were filled in with the median and the feature was correctly classified as numerical. Caveat: contains very similar distributions between the genres. might be removed later on.

12.valence - left as is.

**Unhelpful Features that where removed:**

1.instance_id - only an index.

2.obtained_date - only contains the 4 consecutive dates of data aquisition.

3.instrumentalness - contains 30% missing values.

4.artist_name and track_name - were used to obtain new features and then discarded.


**New features:**

Japanese - This feature indicates wether the track/artist name is written in Japanese. This helps identify the Anime genre.
"""

data.head()

"""## preprocessing"""

data.info()

"""# ML models:
### Logistic regression








"""

from sklearn.linear_model import LogisticRegression

# Separate features and target variable
X = data.drop('music_genre', axis=1)
y = data['music_genre']

# Train-test split
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Fit and predict
logreg = LogisticRegression()
logreg.fit(X_train, y_train)
y_pred = logreg.predict(X_test)

# Classification report
report = classification_report(y_test, y_pred, digits=4, target_names=data['music_genre'].unique(), output_dict=True)
print(classification_report(y_test, y_pred, digits=4, target_names=data['music_genre'].unique()))


# Confusion matrix
conf_mat = confusion_matrix(y_test, y_pred)
print("Confusion Matrix:\n", conf_mat)

# Specificity and Sensitivity
num_classes = len(data['music_genre'].unique())

TP = conf_mat.diagonal()
FP = conf_mat.sum(axis=0) - TP
FN = conf_mat.sum(axis=1) - TP
TN = conf_mat.sum() - TP - FP - FN

specificity = TN / (TN + FP)
sensitivity = TP / (TP + FN)

print(f"Overall Specificity: {specificity.mean():.4f}")
print(f"Overall Sensitivity: {sensitivity.mean():.4f}")

# Precision, Recall, F1-Score
precision = report['macro avg']['precision']
recall = report['macro avg']['recall']
f1_score = report['macro avg']['f1-score']

print(f"Overall Precision: {precision:.4f}")
print(f"Overall Recall: {recall:.4f}")
print(f"Overall F1-Score: {f1_score:.4f}")

# False Positive Rate (FPR) and False Negative Rate (FNR)
num_classes = len(data['music_genre'].unique())

FP = conf_mat.sum(axis=0) - conf_mat.diagonal()
FN = conf_mat.sum(axis=1) - conf_mat.diagonal()

FPR = FP / (FP + conf_mat.sum(axis=1) - FP)
FNR = FN / (FN + conf_mat.sum(axis=0) - FN)

print(f"Overall FPR: {FPR.mean():.4f}")
print(f"Overall FNR: {FNR.mean():.4f}")


# Evaluate
from sklearn.metrics import accuracy_score, classification_report
print("Accuracy:", accuracy_score(y_test, y_pred))

"""### Random Forest"""

from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix

# Separate features and target variable
X = data.drop('music_genre', axis=1)
y = data['music_genre']

# Train-test split
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Fit and predict
rf = RandomForestClassifier()
rf.fit(X_train, y_train)
y_pred = rf.predict(X_test)

# Classification report
report = classification_report(y_test, y_pred, digits=4, target_names=data['music_genre'].unique(), output_dict=True)
print(classification_report(y_test, y_pred, digits=4, target_names=data['music_genre'].unique()))


# Confusion matrix
conf_mat = confusion_matrix(y_test, y_pred)
print("Confusion Matrix:\n", conf_mat)

# Specificity and Sensitivity
num_classes = len(data['music_genre'].unique())

TP = conf_mat.diagonal()
FP = conf_mat.sum(axis=0) - TP
FN = conf_mat.sum(axis=1) - TP
TN = conf_mat.sum() - TP - FP - FN

specificity = TN / (TN + FP)
sensitivity = TP / (TP + FN)

print(f"Overall Specificity: {specificity.mean():.4f}")
print(f"Overall Sensitivity: {sensitivity.mean():.4f}")

# Precision, Recall, F1-Score
precision = report['macro avg']['precision']
recall = report['macro avg']['recall']
f1_score = report['macro avg']['f1-score']

print(f"Overall Precision: {precision:.4f}")
print(f"Overall Recall: {recall:.4f}")
print(f"Overall F1-Score: {f1_score:.4f}")

# False Positive Rate (FPR) and False Negative Rate (FNR)
num_classes = len(data['music_genre'].unique())

FP = conf_mat.sum(axis=0) - conf_mat.diagonal()
FN = conf_mat.sum(axis=1) - conf_mat.diagonal()

FPR = FP / (FP + conf_mat.sum(axis=1) - FP)
FNR = FN / (FN + conf_mat.sum(axis=0) - FN)

print(f"Overall FPR: {FPR.mean():.4f}")
print(f"Overall FNR: {FNR.mean():.4f}")

# Evaluate
from sklearn.metrics import accuracy_score, classification_report
print("Accuracy:", accuracy_score(y_test, y_pred))

"""### Support Vector Machine (SVM)"""

from sklearn.svm import SVC
from sklearn.metrics import classification_report, confusion_matrix

# Separate features and target variable
X = data.drop('music_genre', axis=1)
y = data['music_genre']

# Train-test split
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Fit and predict
svm = SVC()
svm.fit(X_train, y_train)
y_pred = svm.predict(X_test)

# Classification report
report = classification_report(y_test, y_pred, digits=4, target_names=data['music_genre'].unique(), output_dict=True)
print(classification_report(y_test, y_pred, digits=4, target_names=data['music_genre'].unique()))


# Confusion matrix
conf_mat = confusion_matrix(y_test, y_pred)
print("Confusion Matrix:\n", conf_mat)

# Specificity and Sensitivity
num_classes = len(data['music_genre'].unique())

TP = conf_mat.diagonal()
FP = conf_mat.sum(axis=0) - TP
FN = conf_mat.sum(axis=1) - TP
TN = conf_mat.sum() - TP - FP - FN

specificity = TN / (TN + FP)
sensitivity = TP / (TP + FN)

print(f"Overall Specificity: {specificity.mean():.4f}")
print(f"Overall Sensitivity: {sensitivity.mean():.4f}")

# Precision, Recall, F1-Score
precision = report['macro avg']['precision']
recall = report['macro avg']['recall']
f1_score = report['macro avg']['f1-score']

print(f"Overall Precision: {precision:.4f}")
print(f"Overall Recall: {recall:.4f}")
print(f"Overall F1-Score: {f1_score:.4f}")

# False Positive Rate (FPR) and False Negative Rate (FNR)
num_classes = len(data['music_genre'].unique())

FP = conf_mat.sum(axis=0) - conf_mat.diagonal()
FN = conf_mat.sum(axis=1) - conf_mat.diagonal()

FPR = FP / (FP + conf_mat.sum(axis=1) - FP)
FNR = FN / (FN + conf_mat.sum(axis=0) - FN)

print(f"Overall FPR: {FPR.mean():.4f}")
print(f"Overall FNR: {FNR.mean():.4f}")

# Evaluate
from sklearn.metrics import accuracy_score, classification_report
print("Accuracy:", accuracy_score(y_test, y_pred))
print(classification_report(y_test, y_pred))

"""# DL models:

"""

data.info()
data.head()

"""### Multi-layer perceptron (MLP) neural network"""

import numpy as np
from keras.models import Sequential
from keras.layers import Dense
import tensorflow as tf
from sklearn.neural_network import MLPClassifier
from sklearn.neural_network import MLPRegressor
from keras.metrics import SpecificityAtSensitivity
from keras.metrics import SensitivityAtSpecificity

# Convert music genre labels to one-hot encoded vectors
X = data.drop(['music_genre'], axis=1).values
y = pd.get_dummies(df['music_genre'])

# Create a neural network model
model = Sequential()
model.add(Dense(64, input_dim=X.shape[1], activation='relu'))
model.add(Dense(32, activation='relu'))
model.add(Dense(y.shape[1], activation='softmax'))

# Compile the model with categorical cross-entropy as the loss function
model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[SensitivityAtSpecificity(0.5), SpecificityAtSensitivity(0.5)])

# Train the model
model.fit(X, y, epochs=5, batch_size=32, validation_split=0.2)

# Evaluate the model
loss, Precision = model.evaluate(X, y)
print("Categorical cross-entropy loss:", loss)
print("Precision:",Precision)

'''loss, sens, spec = model.evaluate(X, y)
print("Categorical cross-entropy loss:", loss)
print("Sensitivity:", sens)
print("Specificity:", spec)'''
# Confusion matrix
y_pred = model.predict(X_test)
y_pred_classes = np.argmax(y_pred, axis=1)
cm = confusion_matrix(y_test, y_pred_classes)
print(cm)

# create a new track for prediction
new_track = np.array([0.6, 0.2, 0.8, 230000, 0.7, 0.5, -7.2, 0.1, 120.0, 0.5, 30, 1, 0, 1, 0, 0, 0, 0, 0, 0,0, 0, 1, 0])

# make prediction
prediction = model.predict(np.array([new_track]))
predicted_genre = y.columns[np.argmax(prediction)]

# print the predicted genre
print("Predicted music genre:", predicted_genre)

import numpy as np
from keras.models import Sequential
from keras.layers import Dense
import tensorflow as tf
from sklearn.neural_network import MLPClassifier
from sklearn.neural_network import MLPRegressor
# Convert music genre labels to one-hot encoded vectors
X = data.drop(['music_genre'], axis=1).values
y = pd.get_dummies(df['music_genre'])

# Create a neural network model
model = Sequential()
model.add(Dense(64, input_dim=X.shape[1], activation='relu'))
model.add(Dense(32, activation='relu'))
model.add(Dense(y.shape[1], activation='softmax'))

# Compile the model with categorical cross-entropy as the loss function
model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])

# Train the model
model.fit(X, y, epochs=20, batch_size=32, validation_split=0.2)

# Evaluate the model
loss, accuracy = model.evaluate(X, y)
print("Categorical cross-entropy loss:", loss)
print("Accuracy:", accuracy)

# create a new track for prediction
new_track = np.array([0.6, 0.2, 0.8, 230000, 0.7, 0.5, -7.2, 0.1, 120.0, 0.5, 30, 1, 0, 1, 0, 0, 0, 0, 0, 0,0, 0, 1, 0])

# make prediction
prediction = model.predict(np.array([new_track]))
predicted_genre = y.columns[np.argmax(prediction)]

# print the predicted genre
print("Predicted music genre:", predicted_genre)

import numpy as np
from keras.models import Sequential
from keras.layers import Dense
import tensorflow as tf
from sklearn.neural_network import MLPClassifier
from sklearn.neural_network import MLPRegressor
# Convert music genre labels to one-hot encoded vectors
X = data.drop(['music_genre'], axis=1).values
y = pd.get_dummies(df['music_genre'])

# Create a neural network model
model = Sequential()
model.add(Dense(64, input_dim=X.shape[1], activation='relu'))
model.add(Dense(32, activation='relu'))
model.add(Dense(y.shape[1], activation='softmax'))

# Compile the model with categorical cross-entropy as the loss function
model.compile(loss='categorical_crossentropy', optimizer='Nadam', metrics=['accuracy'])

# Train the model
model.fit(X, y, epochs=20, batch_size=32, validation_split=0.2)

# Evaluate the model
loss, accuracy = model.evaluate(X, y)
print("Categorical cross-entropy loss:", loss)
print("Accuracy:", accuracy)

# create a new track for prediction
new_track = np.array([0.6, 0.2, 0.8, 230000, 0.7, 0.5, -7.2, 0.1, 120.0, 0.5, 30, 1, 0, 1, 0, 0, 0, 0, 0, 0,0, 0, 1, 0])

# make prediction
prediction = model.predict(np.array([new_track]))
predicted_genre = y.columns[np.argmax(prediction)]

# print the predicted genre
print("Predicted music genre:", predicted_genre)

import numpy as np
from keras.models import Sequential
from keras.layers import Dense
import tensorflow as tf
from sklearn.neural_network import MLPClassifier
from sklearn.neural_network import MLPRegressor
# Convert music genre labels to one-hot encoded vectors
X = data.drop(['music_genre'], axis=1).values
y = pd.get_dummies(df['music_genre'])

# Create a neural network model
model = Sequential()
model.add(Dense(64, input_dim=X.shape[1], activation='relu'))
model.add(Dense(32, activation='relu'))
model.add(Dense(y.shape[1], activation='softmax'))

# Compile the model with categorical cross-entropy as the loss function
model.compile(loss='categorical_crossentropy', optimizer='Adagrad', metrics=['accuracy'])

# Train the model
model.fit(X, y, epochs=20, batch_size=32, validation_split=0.2)

# Evaluate the model
loss, accuracy = model.evaluate(X, y)
print("Categorical cross-entropy loss:", loss)
print("Accuracy:", accuracy)

# create a new track for prediction
new_track = np.array([0.6, 0.2, 0.8, 230000, 0.7, 0.5, -7.2, 0.1, 120.0, 0.5, 30, 1, 0, 1, 0, 0, 0, 0, 0, 0,0, 0, 1, 0])

# make prediction
prediction = model.predict(np.array([new_track]))
predicted_genre = y.columns[np.argmax(prediction)]

# print the predicted genre
print("Predicted music genre:", predicted_genre)

import numpy as np
from keras.models import Sequential
from keras.layers import Dense
import tensorflow as tf
from sklearn.neural_network import MLPClassifier
from sklearn.neural_network import MLPRegressor
# Convert music genre labels to one-hot encoded vectors
X = data.drop(['music_genre'], axis=1).values
y = pd.get_dummies(df['music_genre'])

# Create a neural network model
model = Sequential()
model.add(Dense(64, input_dim=X.shape[1], activation='relu'))
model.add(Dense(32, activation='relu'))
model.add(Dense(y.shape[1], activation='softmax'))

# Compile the model with categorical cross-entropy as the loss function
model.compile(loss='categorical_crossentropy', optimizer='RMSProp', metrics=['accuracy'])

# Train the model
model.fit(X, y, epochs=20, batch_size=32, validation_split=0.2)

# Evaluate the model
loss, accuracy = model.evaluate(X, y)
print("Categorical cross-entropy loss:", loss)
print("Accuracy:", accuracy)

# create a new track for prediction
new_track = np.array([0.6, 0.2, 0.8, 230000, 0.7, 0.5, -7.2, 0.1, 120.0, 0.5, 30, 1, 0, 1, 0, 0, 0, 0, 0, 0,0, 0, 1, 0])

# make prediction
prediction = model.predict(np.array([new_track]))
predicted_genre = y.columns[np.argmax(prediction)]

# print the predicted genre
print("Predicted music genre:", predicted_genre)

"""### Recurrent Neural Network (RNN):"""

import pandas as pd
import torch
from torch.nn.utils.rnn import pad_sequence
from keras.models import Sequential
from keras.layers import Dense, LSTM, Embedding, Dropout

# Load and preprocess data
X = data.drop(['music_genre'], axis=1).values
y = pd.get_dummies(data['music_genre'])

# Split data into training and testing sets
train_size = int(len(X) * 0.8)
X_train, X_test = X[:train_size], X[train_size:]
y_train, y_test = y[:train_size], y[train_size:]

# Build the RNN model
model = Sequential()
model.add(Dense(64, activation='relu', input_dim=X.shape[1]))
model.add(Dense(32, activation='relu'))
model.add(Dense(y.shape[1], activation='softmax'))
model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

# Train the model
model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)

# Evaluate the model on the test set
loss, accuracy = model.evaluate(X_test, y_test)
print("Categorical cross-entropy loss:", loss)
print("Accuracy:", accuracy)

# Make predictions on new data
new_data = [[0.5, 0.3, 0.7, 200000, 0.8, 0.6, -6.0, 0.05, 120.0, 0.9, 50, 20, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1]]

y_pred = model.predict(new_data)
y_pred_label = y.columns[y_pred.argmax(axis=1)]
print("Predicted genre:", y_pred_label)

import pandas as pd
import torch
from torch.nn.utils.rnn import pad_sequence
from keras.models import Sequential
from keras.layers import Dense, LSTM, Embedding, Dropout

# Load and preprocess data
X = data.drop(['music_genre'], axis=1).values
y = pd.get_dummies(data['music_genre'])

# Split data into training and testing sets
train_size = int(len(X) * 0.8)
X_train, X_test = X[:train_size], X[train_size:]
y_train, y_test = y[:train_size], y[train_size:]

# Build the RNN model
model = Sequential()
model.add(Dense(64, activation='relu', input_dim=X.shape[1]))
model.add(Dense(32, activation='relu'))
model.add(Dense(y.shape[1], activation='softmax'))
model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])

# Train the model
model.fit(X_train, y_train, epochs=20, batch_size=32, validation_split=0.2)

# Evaluate the model on the test set
loss, accuracy = model.evaluate(X_test, y_test)
print("Categorical cross-entropy loss:", loss)
print("Accuracy:", accuracy)

# Make predictions on new data
new_data = [[0.5, 0.3, 0.7, 200000, 0.8, 0.6, -6.0, 0.05, 120.0, 0.9, 50, 20, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1]]

y_pred = model.predict(new_data)
y_pred_label = y.columns[y_pred.argmax(axis=1)]
print("Predicted genre:", y_pred_label)

import pandas as pd
import torch
from torch.nn.utils.rnn import pad_sequence
from keras.models import Sequential
from keras.layers import Dense, LSTM, Embedding, Dropout

# Load and preprocess data
X = data.drop(['music_genre'], axis=1).values
y = pd.get_dummies(data['music_genre'])

# Split data into training and testing sets
train_size = int(len(X) * 0.8)
X_train, X_test = X[:train_size], X[train_size:]
y_train, y_test = y[:train_size], y[train_size:]

# Build the RNN model
model = Sequential()
model.add(Dense(64, activation='relu', input_dim=X.shape[1]))
model.add(Dense(32, activation='relu'))
model.add(Dense(y.shape[1], activation='softmax'))
model.compile(loss='categorical_crossentropy', optimizer='Nadam', metrics=['accuracy'])

# Train the model
model.fit(X_train, y_train, epochs=20, batch_size=32, validation_split=0.2)

# Evaluate the model on the test set
loss, accuracy = model.evaluate(X_test, y_test)
print("Categorical cross-entropy loss:", loss)
print("Accuracy:", accuracy)

# Make predictions on new data
new_data = [[0.5, 0.3, 0.7, 200000, 0.8, 0.6, -6.0, 0.05, 120.0, 0.9, 50, 20, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1]]

y_pred = model.predict(new_data)
y_pred_label = y.columns[y_pred.argmax(axis=1)]
print("Predicted genre:", y_pred_label)

import pandas as pd
import torch
from torch.nn.utils.rnn import pad_sequence
from keras.models import Sequential
from keras.layers import Dense, LSTM, Embedding, Dropout

# Load and preprocess data
X = data.drop(['music_genre'], axis=1).values
y = pd.get_dummies(data['music_genre'])

# Split data into training and testing sets
train_size = int(len(X) * 0.8)
X_train, X_test = X[:train_size], X[train_size:]
y_train, y_test = y[:train_size], y[train_size:]

# Build the RNN model
model = Sequential()
model.add(Dense(64, activation='relu', input_dim=X.shape[1]))
model.add(Dense(32, activation='relu'))
model.add(Dense(y.shape[1], activation='softmax'))
model.compile(loss='categorical_crossentropy', optimizer='Adagrad', metrics=['accuracy'])

# Train the model
model.fit(X_train, y_train, epochs=20, batch_size=32, validation_split=0.2)

# Evaluate the model on the test set
loss, accuracy = model.evaluate(X_test, y_test)
print("Categorical cross-entropy loss:", loss)
print("Accuracy:", accuracy)

# Make predictions on new data
new_data = [[0.5, 0.3, 0.7, 200000, 0.8, 0.6, -6.0, 0.05, 120.0, 0.9, 50, 20, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1]]

y_pred = model.predict(new_data)
y_pred_label = y.columns[y_pred.argmax(axis=1)]
print("Predicted genre:", y_pred_label)

import pandas as pd
import torch
from torch.nn.utils.rnn import pad_sequence
from keras.models import Sequential
from keras.layers import Dense, LSTM, Embedding, Dropout

# Load and preprocess data
X = data.drop(['music_genre'], axis=1).values
y = pd.get_dummies(data['music_genre'])

# Split data into training and testing sets
train_size = int(len(X) * 0.8)
X_train, X_test = X[:train_size], X[train_size:]
y_train, y_test = y[:train_size], y[train_size:]

# Build the RNN model
model = Sequential()
model.add(Dense(64, activation='relu', input_dim=X.shape[1]))
model.add(Dense(32, activation='relu'))
model.add(Dense(y.shape[1], activation='softmax'))
model.compile(loss='categorical_crossentropy', optimizer='RMSProp', metrics=['accuracy'])

# Train the model
model.fit(X_train, y_train, epochs=20, batch_size=32, validation_split=0.2)

# Evaluate the model on the test set
loss, accuracy = model.evaluate(X_test, y_test)
print("Categorical cross-entropy loss:", loss)
print("Accuracy:", accuracy)

# Make predictions on new data
new_data = [[0.5, 0.3, 0.7, 200000, 0.8, 0.6, -6.0, 0.05, 120.0, 0.9, 50, 20, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1]]

y_pred = model.predict(new_data)
y_pred_label = y.columns[y_pred.argmax(axis=1)]
print("Predicted genre:", y_pred_label)

"""### Random Forest Classifier."""

print(data.head(1))

import numpy as np
import pandas as pd
import tensorflow as tf
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler


# Encode categorical data
encoder = LabelEncoder()
data['music_genre'] = encoder.fit_transform(data['music_genre'])

# Split the data into features and target
X = data.drop(['music_genre'], axis=1).values
y = data['music_genre'].values

# Split the data into train and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Scale the features
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Define the model
model = tf.keras.models.Sequential([
    tf.keras.layers.Dense(128, input_shape=(X_train.shape[1],), activation='relu'),
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dense(32, activation='relu'),
    tf.keras.layers.Dense(10, activation='softmax')
])

# Compile the model
model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

# Train the model
history = model.fit(X_train, y_train, epochs=14, validation_data=(X_test, y_test))

# Evaluate the model on the test set
test_loss, test_acc = model.evaluate(X_test, y_test)
print('Test accuracy:', test_acc)

# Confusion matrix
y_pred = model.predict(X_test)
y_pred_classes = np.argmax(y_pred, axis=1)
cm = confusion_matrix(y_test, y_pred_classes)
print(cm)

# Make predictions on new data
X_new = np.array([[27.0,0.00468, 0.652,227360.0, 0.941, 0.115, -5.201,0.0748, 100.889, 0.759,45,1, 0, 1, 0, 0, 0, 0, 0,1,0, 0, 1, 0
 ]])
X_new = scaler.transform(X_new)
y_pred = model.predict(X_new)
y_pred_label = encoder.inverse_transform(np.argmax(y_pred, axis=-1))
print('Predicted genre:', y_pred_label[0])

import numpy as np
import pandas as pd
import tensorflow as tf
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler


# Encode categorical data
encoder = LabelEncoder()
data['music_genre'] = encoder.fit_transform(data['music_genre'])

# Split the data into features and target
X = data.drop(['music_genre'], axis=1).values
y = data['music_genre'].values

# Split the data into train and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Scale the features
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Define the model
model = tf.keras.models.Sequential([
    tf.keras.layers.Dense(128, input_shape=(X_train.shape[1],), activation='relu'),
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dense(32, activation='relu'),
    tf.keras.layers.Dense(10, activation='softmax')
])

# Compile the model
model.compile(loss='sparse_categorical_crossentropy', optimizer='RMSProp', metrics=['accuracy'])

# Train the model
history = model.fit(X_train, y_train, epochs=14, validation_data=(X_test, y_test))

# Evaluate the model on the test set
test_loss, test_acc = model.evaluate(X_test, y_test)
print('Test accuracy:', test_acc)

# Confusion matrix
y_pred = model.predict(X_test)
y_pred_classes = np.argmax(y_pred, axis=1)
cm = confusion_matrix(y_test, y_pred_classes)
print(cm)

# Make predictions on new data
X_new = np.array([[27.0,0.00468, 0.652,227360.0, 0.941, 0.115, -5.201,0.0748, 100.889, 0.759,45,1, 0, 1, 0, 0, 0, 0, 0,1,0, 0, 1, 0
 ]])
X_new = scaler.transform(X_new)
y_pred = model.predict(X_new)
y_pred_label = encoder.inverse_transform(np.argmax(y_pred, axis=-1))
print('Predicted genre:', y_pred_label[0])

import numpy as np
import pandas as pd
import tensorflow as tf
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler


# Encode categorical data
encoder = LabelEncoder()
data['music_genre'] = encoder.fit_transform(data['music_genre'])

# Split the data into features and target
X = data.drop(['music_genre'], axis=1).values
y = data['music_genre'].values

# Split the data into train and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Scale the features
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Define the model
model = tf.keras.models.Sequential([
    tf.keras.layers.Dense(128, input_shape=(X_train.shape[1],), activation='relu'),
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dense(32, activation='relu'),
    tf.keras.layers.Dense(10, activation='softmax')
])

# Compile the model
model.compile(loss='sparse_categorical_crossentropy', optimizer='Nadam', metrics=['accuracy'])

# Train the model
history = model.fit(X_train, y_train, epochs=14, validation_data=(X_test, y_test))

# Evaluate the model on the test set
test_loss, test_acc = model.evaluate(X_test, y_test)
print('Test accuracy:', test_acc)

# Confusion matrix
y_pred = model.predict(X_test)
y_pred_classes = np.argmax(y_pred, axis=1)
cm = confusion_matrix(y_test, y_pred_classes)
print(cm)

# Make predictions on new data
X_new = np.array([[27.0,0.00468, 0.652,227360.0, 0.941, 0.115, -5.201,0.0748, 100.889, 0.759,45,1, 0, 1, 0, 0, 0, 0, 0,1,0, 0, 1, 0
 ]])
X_new = scaler.transform(X_new)
y_pred = model.predict(X_new)
y_pred_label = encoder.inverse_transform(np.argmax(y_pred, axis=-1))
print('Predicted genre:', y_pred_label[0])

import numpy as np
import pandas as pd
import tensorflow as tf
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler


# Encode categorical data
encoder = LabelEncoder()
data['music_genre'] = encoder.fit_transform(data['music_genre'])

# Split the data into features and target
X = data.drop(['music_genre'], axis=1).values
y = data['music_genre'].values

# Split the data into train and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Scale the features
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Define the model
model = tf.keras.models.Sequential([
    tf.keras.layers.Dense(128, input_shape=(X_train.shape[1],), activation='relu'),
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dense(32, activation='relu'),
    tf.keras.layers.Dense(10, activation='softmax')
])

# Compile the model
model.compile(loss='sparse_categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])

# Train the model
history = model.fit(X_train, y_train, epochs=14, validation_data=(X_test, y_test))

# Evaluate the model on the test set
test_loss, test_acc = model.evaluate(X_test, y_test)
print('Test accuracy:', test_acc)

# Confusion matrix
y_pred = model.predict(X_test)
y_pred_classes = np.argmax(y_pred, axis=1)
cm = confusion_matrix(y_test, y_pred_classes)
print(cm)

# Make predictions on new data
X_new = np.array([[27.0,0.00468, 0.652,227360.0, 0.941, 0.115, -5.201,0.0748, 100.889, 0.759,45,1, 0, 1, 0, 0, 0, 0, 0,1,0, 0, 1, 0
 ]])
X_new = scaler.transform(X_new)
y_pred = model.predict(X_new)
y_pred_label = encoder.inverse_transform(np.argmax(y_pred, axis=-1))
print('Predicted genre:', y_pred_label[0])

import numpy as np
import pandas as pd
import tensorflow as tf
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler


# Encode categorical data
encoder = LabelEncoder()
data['music_genre'] = encoder.fit_transform(data['music_genre'])

# Split the data into features and target
X = data.drop(['music_genre'], axis=1).values
y = data['music_genre'].values

# Split the data into train and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Scale the features
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Define the model
model = tf.keras.models.Sequential([
    tf.keras.layers.Dense(128, input_shape=(X_train.shape[1],), activation='relu'),
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dense(32, activation='relu'),
    tf.keras.layers.Dense(10, activation='softmax')
])

# Compile the model
model.compile(loss='sparse_categorical_crossentropy', optimizer='Adagrad', metrics=['accuracy'])

# Train the model
history = model.fit(X_train, y_train, epochs=14, validation_data=(X_test, y_test))

# Evaluate the model on the test set
test_loss, test_acc = model.evaluate(X_test, y_test)
print('Test accuracy:', test_acc)

# Confusion matrix
y_pred = model.predict(X_test)
y_pred_classes = np.argmax(y_pred, axis=1)
cm = confusion_matrix(y_test, y_pred_classes)
print(cm)

# Make predictions on new data
X_new = np.array([[27.0,0.00468, 0.652,227360.0, 0.941, 0.115, -5.201,0.0748, 100.889, 0.759,45,1, 0, 1, 0, 0, 0, 0, 0,1,0, 0, 1, 0
 ]])
X_new = scaler.transform(X_new)
y_pred = model.predict(X_new)
y_pred_label = encoder.inverse_transform(np.argmax(y_pred, axis=-1))
print('Predicted genre:', y_pred_label[0])

"""### CNN model"""

import numpy as np
import pandas as pd
import tensorflow as tf
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from keras.metrics import SpecificityAtSensitivity
from keras.metrics import SensitivityAtSpecificity
from sklearn.svm import SVC

X = data.drop('music_genre', axis=1)
y = data['music_genre']


# Encode labels
label_encoder = LabelEncoder()
y = label_encoder.fit_transform(y)

# Split data into train and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Scale input features
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Reshape input features for CNN
X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)
X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)

# Define CNN architecture
model = tf.keras.Sequential([
    tf.keras.layers.Conv1D(filters=32, kernel_size=3, activation='relu', input_shape=(X_train.shape[1], 1)),
    tf.keras.layers.BatchNormalization(),
    tf.keras.layers.MaxPooling1D(pool_size=2),
    tf.keras.layers.Dropout(0.2),
    tf.keras.layers.Conv1D(filters=64, kernel_size=3, activation='relu'),
    tf.keras.layers.BatchNormalization(),
    tf.keras.layers.MaxPooling1D(pool_size=2),
    tf.keras.layers.Dropout(0.2),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.BatchNormalization(),
    tf.keras.layers.Dropout(0.5),
    tf.keras.layers.Dense(10, activation='softmax')
])

# Compile model
model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

# Train model
history = model.fit(X_train, y_train, epochs=14, validation_data=(X_test, y_test))

# Evaluate model
loss, accuracy = model.evaluate(X_test, y_test)
print(f'Test loss: {loss:.3f}, Test accuracy: {accuracy:.3f}')

# Confusion matrix
y_pred = model.predict(X_test)
y_pred_classes = np.argmax(y_pred, axis=1)
cm = confusion_matrix(y_test, y_pred_classes)
print(cm)

# create a new track for prediction
new_track = np.array([0.6, 0.2, 0.8, 230000, 0.7, 0.5, -7.2, 0.1, 120.0, 0.5, 30, 1, 0, 1, 0, 0, 0, 0, 0, 0,0, 0, 1, 0])

# reshape the input to match the CNN model input shape
new_track = new_track.reshape(24, 1)

# make prediction
prediction = model.predict(np.array([new_track]))
predicted_genre_index = np.argmax(prediction)
predicted_genre = y[predicted_genre_index]

# print the predicted genre
print("Predicted music genre:", predicted_genre)

import numpy as np
import pandas as pd
import tensorflow as tf
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler

X = data.drop('music_genre', axis=1)
y = data['music_genre']


# Encode labels
label_encoder = LabelEncoder()
y = label_encoder.fit_transform(y)

# Split data into train and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Scale input features
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Reshape input features for CNN
X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)
X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)

# Define CNN architecture
model = tf.keras.Sequential([
    tf.keras.layers.Conv1D(filters=32, kernel_size=3, activation='relu', input_shape=(X_train.shape[1], 1)),
    tf.keras.layers.BatchNormalization(),
    tf.keras.layers.MaxPooling1D(pool_size=2),
    tf.keras.layers.Dropout(0.2),
    tf.keras.layers.Conv1D(filters=64, kernel_size=3, activation='relu'),
    tf.keras.layers.BatchNormalization(),
    tf.keras.layers.MaxPooling1D(pool_size=2),
    tf.keras.layers.Dropout(0.2),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.BatchNormalization(),
    tf.keras.layers.Dropout(0.5),
    tf.keras.layers.Dense(10, activation='softmax')
])

# Compile model
model.compile(loss='sparse_categorical_crossentropy', optimizer='Nadam', metrics=['accuracy'])

# Train model
history = model.fit(X_train, y_train, epochs=14, validation_data=(X_test, y_test))

# Evaluate model
loss, accuracy = model.evaluate(X_test, y_test)
print(f'Test loss: {loss:.3f}, Test accuracy: {accuracy:.3f}')

# Confusion matrix
y_pred = model.predict(X_test)
y_pred_classes = np.argmax(y_pred, axis=1)
cm = confusion_matrix(y_test, y_pred_classes)
print(cm)

# create a new track for prediction
new_track = np.array([0.6, 0.2, 0.8, 230000, 0.7, 0.5, -7.2, 0.1, 120.0, 0.5, 30, 1, 0, 1, 0, 0, 0, 0, 0, 0,0, 0, 1, 0])

# reshape the input to match the CNN model input shape
new_track = new_track.reshape(24, 1)

# make prediction
prediction = model.predict(np.array([new_track]))
predicted_genre_index = np.argmax(prediction)
predicted_genre = y[predicted_genre_index]

# print the predicted genre
print("Predicted music genre:", predicted_genre)

import numpy as np
import pandas as pd
import tensorflow as tf
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler

X = data.drop('music_genre', axis=1)
y = data['music_genre']


# Encode labels
label_encoder = LabelEncoder()
y = label_encoder.fit_transform(y)

# Split data into train and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Scale input features
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Reshape input features for CNN
X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)
X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)

# Define CNN architecture
model = tf.keras.Sequential([
    tf.keras.layers.Conv1D(filters=32, kernel_size=3, activation='relu', input_shape=(X_train.shape[1], 1)),
    tf.keras.layers.BatchNormalization(),
    tf.keras.layers.MaxPooling1D(pool_size=2),
    tf.keras.layers.Dropout(0.2),
    tf.keras.layers.Conv1D(filters=64, kernel_size=3, activation='relu'),
    tf.keras.layers.BatchNormalization(),
    tf.keras.layers.MaxPooling1D(pool_size=2),
    tf.keras.layers.Dropout(0.2),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.BatchNormalization(),
    tf.keras.layers.Dropout(0.5),
    tf.keras.layers.Dense(10, activation='softmax')
])

# Compile model
model.compile(loss='sparse_categorical_crossentropy', optimizer='RMSProp', metrics=['accuracy'])

# Train model
history = model.fit(X_train, y_train, epochs=14, validation_data=(X_test, y_test))

# Evaluate model
loss, accuracy = model.evaluate(X_test, y_test)
print(f'Test loss: {loss:.3f}, Test accuracy: {accuracy:.3f}')

# Confusion matrix
y_pred = model.predict(X_test)
y_pred_classes = np.argmax(y_pred, axis=1)
cm = confusion_matrix(y_test, y_pred_classes)
print(cm)

# create a new track for prediction
new_track = np.array([0.6, 0.2, 0.8, 230000, 0.7, 0.5, -7.2, 0.1, 120.0, 0.5, 30, 1, 0, 1, 0, 0, 0, 0, 0, 0,0, 0, 1, 0])

# reshape the input to match the CNN model input shape
new_track = new_track.reshape(24, 1)

# make prediction
prediction = model.predict(np.array([new_track]))
predicted_genre_index = np.argmax(prediction)
predicted_genre = y[predicted_genre_index]

# print the predicted genre
print("Predicted music genre:", predicted_genre)

import numpy as np
import pandas as pd
import tensorflow as tf
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler

X = data.drop('music_genre', axis=1)
y = data['music_genre']


# Encode labels
label_encoder = LabelEncoder()
y = label_encoder.fit_transform(y)

# Split data into train and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Scale input features
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Reshape input features for CNN
X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)
X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)

# Define CNN architecture
model = tf.keras.Sequential([
    tf.keras.layers.Conv1D(filters=32, kernel_size=3, activation='relu', input_shape=(X_train.shape[1], 1)),
    tf.keras.layers.BatchNormalization(),
    tf.keras.layers.MaxPooling1D(pool_size=2),
    tf.keras.layers.Dropout(0.2),
    tf.keras.layers.Conv1D(filters=64, kernel_size=3, activation='relu'),
    tf.keras.layers.BatchNormalization(),
    tf.keras.layers.MaxPooling1D(pool_size=2),
    tf.keras.layers.Dropout(0.2),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.BatchNormalization(),
    tf.keras.layers.Dropout(0.5),
    tf.keras.layers.Dense(10, activation='softmax')
])

# Compile model
model.compile(loss='sparse_categorical_crossentropy', optimizer='Adagrad', metrics=['accuracy'])

# Train model
history = model.fit(X_train, y_train, epochs=14, validation_data=(X_test, y_test))

# Evaluate model
loss, accuracy = model.evaluate(X_test, y_test)
print(f'Test loss: {loss:.3f}, Test accuracy: {accuracy:.3f}')

# Confusion matrix
y_pred = model.predict(X_test)
y_pred_classes = np.argmax(y_pred, axis=1)
cm = confusion_matrix(y_test, y_pred_classes)
print(cm)

# create a new track for prediction
new_track = np.array([0.6, 0.2, 0.8, 230000, 0.7, 0.5, -7.2, 0.1, 120.0, 0.5, 30, 1, 0, 1, 0, 0, 0, 0, 0, 0,0, 0, 1, 0])

# reshape the input to match the CNN model input shape
new_track = new_track.reshape(24, 1)

# make prediction
prediction = model.predict(np.array([new_track]))
predicted_genre_index = np.argmax(prediction)
predicted_genre = y[predicted_genre_index]

# print the predicted genre
print("Predicted music genre:", predicted_genre)

import numpy as np
import pandas as pd
import tensorflow as tf
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler

X = data.drop('music_genre', axis=1)
y = data['music_genre']


# Encode labels
label_encoder = LabelEncoder()
y = label_encoder.fit_transform(y)

# Split data into train and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Scale input features
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Reshape input features for CNN
X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)
X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)

# Define CNN architecture
model = tf.keras.Sequential([
    tf.keras.layers.Conv1D(filters=32, kernel_size=3, activation='relu', input_shape=(X_train.shape[1], 1)),
    tf.keras.layers.BatchNormalization(),
    tf.keras.layers.MaxPooling1D(pool_size=2),
    tf.keras.layers.Dropout(0.2),
    tf.keras.layers.Conv1D(filters=64, kernel_size=3, activation='relu'),
    tf.keras.layers.BatchNormalization(),
    tf.keras.layers.MaxPooling1D(pool_size=2),
    tf.keras.layers.Dropout(0.2),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.BatchNormalization(),
    tf.keras.layers.Dropout(0.5),
    tf.keras.layers.Dense(10, activation='softmax')
])

# Compile model
model.compile(loss='sparse_categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])

# Train model
history = model.fit(X_train, y_train, epochs=14, validation_data=(X_test, y_test))

# Evaluate model
loss, accuracy = model.evaluate(X_test, y_test)
print(f'Test loss: {loss:.3f}, Test accuracy: {accuracy:.3f}')

# Confusion matrix
y_pred = model.predict(X_test)
y_pred_classes = np.argmax(y_pred, axis=1)
cm = confusion_matrix(y_test, y_pred_classes)
print(cm)

# create a new track for prediction
new_track = np.array([0.6, 0.2, 0.8, 230000, 0.7, 0.5, -7.2, 0.1, 120.0, 0.5, 30, 1, 0, 1, 0, 0, 0, 0, 0, 0,0, 0, 1, 0])

# reshape the input to match the CNN model input shape
new_track = new_track.reshape(24, 1)

# make prediction
prediction = model.predict(np.array([new_track]))
predicted_genre_index = np.argmax(prediction)
predicted_genre = y[predicted_genre_index]

# print the predicted genre
print("Predicted music genre:", predicted_genre)